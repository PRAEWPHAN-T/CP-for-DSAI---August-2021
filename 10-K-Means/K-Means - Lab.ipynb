{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Modify the scratch code of K-means clustering in our lecture:\r\n",
    "- Modify so it print out the total within-cluster variation.  Then try to run several k and identify which k is best.\r\n",
    "- Since k-means can be slow due to its pairwise computations, let's implement a mini-batch k-means in which the cluster is create using only partial subset of samples.\r\n",
    "- Put everything into a class\r\n",
    "\r\n",
    "Mini-Batch will rarely converge, thus it is important to add a max_iteration or some tolerance.  Last, theoretically speaking, Mini-Batch will never perform better in terms of accuracy when compare to K-means, but it is very close to optimal but will almost always beat K-means in terms of time given large dataset and a modest tolerance parameter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin\r\n",
    "from sklearn.datasets import make_blobs\r\n",
    "from time import time\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "X, y_true = make_blobs(n_samples=1500, centers=4,\r\n",
    "                       cluster_std=0.60, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class Mini_KMeans:\r\n",
    "    def __init__(self, k, replacement=True, batch_size=100, max_iter=100):\r\n",
    "        self.k = k\r\n",
    "        self.replacement=replacement\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.max_iter = max_iter\r\n",
    "\r\n",
    "    def fit(self, X):\r\n",
    "            m, n = X.shape\r\n",
    "\r\n",
    "            #1. randomly choose k clusters from X\r\n",
    "            rng = np.random.RandomState(99)\r\n",
    "            i = rng.permutation(m)[:self.k]\r\n",
    "            self.centers = X[i]\r\n",
    "\r\n",
    "            #having max iter makes sure it will stop eventually\r\n",
    "            for ix in np.arange(self.max_iter):\r\n",
    "                random = rng.randint(m)\r\n",
    "                X_batch = X[random:random+self.batch_size]\r\n",
    "            \r\n",
    "                #2. assign labels based on closest center\r\n",
    "                labels = pairwise_distances_argmin(X_batch, self.centers) \r\n",
    "                \r\n",
    "                # print(labels)\r\n",
    "                # if K = 2 labels = {0,1}\r\n",
    "                # if K = 3 labels = {0,1,2} \r\n",
    "                # print(len(labels))\r\n",
    "\r\n",
    "                #3. find new centers\r\n",
    "                new_centers = []\r\n",
    "                for i in range(self.k):\r\n",
    "                    new_centers.append(X_batch[labels == i].mean(axis=0))\r\n",
    "                    \r\n",
    "                #convert list to np.array; you can actually combine #3\r\n",
    "                #with np.array in one sentence \r\n",
    "                new_centers = np.array(new_centers)\r\n",
    "                # print(new_centers)\r\n",
    "                \r\n",
    "                #4 stopping criteria - if centers do not \r\n",
    "                #change anymore, we stop!\r\n",
    "                #make sure to add rtol or atol since mini-batch does not converge\r\n",
    "                if(np.allclose(self.centers, new_centers, rtol=0.2)):\r\n",
    "                    break\r\n",
    "                else:\r\n",
    "                    self.centers = new_centers\r\n",
    "\r\n",
    "            print(f\"Done in {ix} iterations\")\r\n",
    "\r\n",
    "            #compute total within-variation score\r\n",
    "            total_with_variation_score = 0\r\n",
    "            labels = pairwise_distances_argmin(X, self.centers) #<---Note I use X here.  Why? maybe beacuse you want to use X to find total varience of all X samples. Since, at first you try with batch size.\r\n",
    "            # print(labels[0:100])\r\n",
    "            # print(\"all\" ,len(labels))\r\n",
    "            for i in range(self.k):\r\n",
    "                cluster_mean = X[labels==i].mean(axis=0)\r\n",
    "                total_with_variation_score += ((X[labels==i] - cluster_mean)** 2).sum()\r\n",
    "                \r\n",
    "            print(\"Total with variation score: \", total_with_variation_score)\r\n",
    "\r\n",
    "    def predict(self, X):\r\n",
    "        return pairwise_distances_argmin(X, self.centers)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for k in range(2,7):\r\n",
    "    print(f\"=====k = {k}\")\r\n",
    "    start = time()\r\n",
    "    model = Mini_KMeans(k)\r\n",
    "    model.fit(X)\r\n",
    "    preds = model.predict(X)\r\n",
    "    print(f\"Fit and predict time {time() - start}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=====k = 2\n",
      "Done in 6 iterations\n",
      "Total with variation score:  5859.027548790498\n",
      "Fit and predict time 0.008982419967651367\n",
      "=====k = 3\n",
      "Done in 3 iterations\n",
      "Total with variation score:  2849.7266714358066\n",
      "Fit and predict time 0.00996541976928711\n",
      "=====k = 4\n",
      "Done in 9 iterations\n",
      "Total with variation score:  1007.7374341654453\n",
      "Fit and predict time 0.011969566345214844\n",
      "=====k = 5\n",
      "Done in 9 iterations\n",
      "Total with variation score:  920.8127407429872\n",
      "Fit and predict time 0.01296377182006836\n",
      "=====k = 6\n",
      "Done in 3 iterations\n",
      "Total with variation score:  841.4034939553978\n",
      "Fit and predict time 0.004984855651855469\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "for k in range(8,10):\r\n",
    "    print(f\"=====k = {k}\")\r\n",
    "    start = time()\r\n",
    "    model = Mini_KMeans(k)\r\n",
    "    model.fit(X)\r\n",
    "    preds = model.predict(X)\r\n",
    "    print(f\"Fit and predict time {time() - start}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=====k = 8\n",
      "Done in 3 iterations\n",
      "Total with variation score:  759.7370521508722\n",
      "Fit and predict time 0.018947601318359375\n",
      "=====k = 9\n",
      "Done in 3 iterations\n",
      "Total with variation score:  710.4237667135648\n",
      "Fit and predict time 0.010972023010253906\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "K = 5 is the best get less variation score after K = 5 variation not much change "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "9d3bae0a0f66551680ef8a166f6b92cc2774d5d7901f027deb7bb883ed06d5ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}