{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import random\r\n",
    "class Node:\r\n",
    "    def __init__(self, predicted_class):\r\n",
    "        self.predicted_class = predicted_class\r\n",
    "        self.feature_index = 0\r\n",
    "        self.threshold = 0\r\n",
    "        self.left = None\r\n",
    "        self.right = None\r\n",
    "\r\n",
    "\r\n",
    "class DecisionTree:\r\n",
    "    def __init__(self, max_depth=None):\r\n",
    "        self.max_depth = max_depth\r\n",
    "\r\n",
    "    def split_data(self,X,y):\r\n",
    "        idx = np.arange(0,y.shape[0])\r\n",
    "        percent_train = .6\r\n",
    "        random.shuffle(idx)\r\n",
    "        idx_train = idx[0:int(percent_train*len(X))]\r\n",
    "        idx_test = idx[len(idx_train):len(idx)]\r\n",
    "\r\n",
    "        X_train = X[idx_train]\r\n",
    "        X_test = X[idx_test]\r\n",
    "        y_train = y[idx_train]\r\n",
    "        y_test = y[idx_test]\r\n",
    "        return idx, X_train, y_train, X_test, y_test\r\n",
    "\r\n",
    "    def fit(self, X, y):\r\n",
    "        self.n_classes_ = len(set(y))\r\n",
    "        self.n_features_ = X.shape[1]\r\n",
    "        self.tree_ = self._grow_tree(X, y)\r\n",
    "\r\n",
    "    def predict(self, X):\r\n",
    "        return [self._predict(inputs) for inputs in X]\r\n",
    "\r\n",
    "    def _best_split(self, X, y):\r\n",
    "        m = y.size\r\n",
    "        if m <= 1:\r\n",
    "            return None, None\r\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)] #[50,50,50] # Count of each class in the current node.\r\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)# Gini of parent node.\r\n",
    "        best_idx, best_thr = None, None\r\n",
    "        # Loop through all features.\r\n",
    "        for idx in range(self.n_features_):\r\n",
    "            # Sort data along selected feature.\r\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y))) #thresholds.. #[2, 3, 10, 19]\r\n",
    "            num_left = [0] * self.n_classes_ #[0,0,0]\r\n",
    "            num_right = num_parent.copy() #[50,50,50]\r\n",
    "            for i in range(1, m):\r\n",
    "                c = classes[i - 1]                \r\n",
    "                num_left[c] += 1                \r\n",
    "                num_right[c] -= 1\r\n",
    "                \r\n",
    "                gini_left = 1.0 - sum(\r\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\r\n",
    "                )\r\n",
    "                #we divided by n_samples - i since we know that the left amount of samples\r\n",
    "                #since left side has already i samples\r\n",
    "                gini_right = 1.0 - sum(\r\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\r\n",
    "                )\r\n",
    "                #weighted gini \r\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\r\n",
    "                \r\n",
    "                if thresholds[i] == thresholds[i - 1]:\r\n",
    "                    continue\r\n",
    "                if gini < best_gini:\r\n",
    "                    best_gini = gini\r\n",
    "                    best_idx = idx  #feature_ix\r\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2 #sample_sorted[i]\r\n",
    "        return best_idx, best_thr #best_indexfeature and thershold\r\n",
    "\r\n",
    "    def _grow_tree(self, X, y, depth=0):\r\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]# each y value of each element [50,50,50]\r\n",
    "        predicted_class = np.argmax(num_samples_per_class) # return index that get max values\r\n",
    "        node = Node(predicted_class=predicted_class)\r\n",
    "\r\n",
    "        if depth < self.max_depth:\r\n",
    "            idx, thr = self._best_split(X, y)\r\n",
    "            if idx is not None:\r\n",
    "                indices_left = X[:, idx] < thr                \r\n",
    "                X_left, y_left = X[indices_left], y[indices_left]                \r\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\r\n",
    "                \r\n",
    "                \r\n",
    "                #take note for later decision\r\n",
    "                node.feature_index = idx\r\n",
    "                node.threshold = thr\r\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\r\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\r\n",
    "                \r\n",
    "        return node\r\n",
    "\r\n",
    "    def _predict(self, inputs):\r\n",
    "        node = self.tree_\r\n",
    "        while node.left:\r\n",
    "            if inputs[node.feature_index] < node.threshold:\r\n",
    "                node = node.left\r\n",
    "            else:\r\n",
    "                node = node.right\r\n",
    "        #choose left or right node from input\r\n",
    "        \r\n",
    "        return node.predicted_class\r\n",
    "\r\n",
    "    def accuracy(self,y,ypred):\r\n",
    "      acc=accuracy_score(y, ypred) #list\r\n",
    "      return acc\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    import sys\r\n",
    "    from sklearn.datasets import load_iris\r\n",
    "\r\n",
    "    dataset = load_iris()\r\n",
    "    X, y = dataset.data, dataset.target\r\n",
    "    clf = DecisionTree(max_depth=10)\r\n",
    "    clf.fit(X, y)\r\n",
    "\r\n",
    "    #pridict from input example\r\n",
    "    print(clf.predict([[0, 0, 5, 1.5]]))\r\n",
    "\r\n",
    "    #pridict from 1 example\r\n",
    "    pred = clf.predict([X[0]])\r\n",
    "    acc=clf.accuracy([y[0]],[pred])\r\n",
    "    print(pred,acc)\r\n",
    "\r\n",
    "    #pridict data split train test\r\n",
    "    idx, X_train, y_train, X_test, y_test = clf.split_data(X, y)\r\n",
    "    pred = clf.predict(X_test)\r\n",
    "    acc=clf.accuracy(y_test,pred)\r\n",
    "    print(pred,acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2]\n",
      "[0] 1.0\n",
      "[0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 2, 0, 1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 0, 0, 0, 2, 2] 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9d3bae0a0f66551680ef8a166f6b92cc2774d5d7901f027deb7bb883ed06d5ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}